# 한눈에 보는 머신러닝

> 머신러닝이란 데이터로부터 학습할 수 있는 시스템을 만드는 것
> 
> 
> 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.
> 
- Training set: 시스템이 학습하는 데 사용하는 샘플
- Training instance: 각각의 훈련 데이터
- Model: 머신러닝 시스템에서 학습하고 예측을 만드는 부분
    - Neural network
    - Random forest
- Data Mining: 대용량의 데이터를 분석하여 숨겨진 패턴을 발견하는 것

# 머신러닝 시스템의 종류

### 훈련 지도 방식

- Supervised learning
    
    알고리즘에 주입하는 훈련 데이터에 label이라는 원하는 답이 포함
    
    - Classification
        
        예시: 로지스틱 회귀(클래스에 속할 확률을 출력)
        
    - Regression(feature를 사용해 target 수치를 예측)
        
        주어진 입력 특성으로 값을 예측 (일반적으로 입력 특성이 여러 개 있으며 이따금 값을 여러개 출력하기도 함)
        
- Unsupervised learning
    
    시스템이 label의 도움없이 학습
    
    - Hierarchical clustering: 각 그룹을 더 작은 그룹으로 세분화 가능
    - Visualization: 레이블이 없는 대규모의 고차원 데이터를 넣으면 도식화 가능한 표현을 만들어주는 알고리즘
    - Dimensionality reduction, Feature extraction: 너무 많은 정보를 잃지 않으면서 데이터를 간소화하기 위해 상관관계가 있는 여러 특성을 하나로 합치는 과정
    - Outlier detection(이상치 탐지): 학습 알고리즘에 주입하기 전에 데이터셋에서 이상한 값을 자동으로 제거하는 것
    - Novelty detection(특이치 탐지): 훈련 세트에 있는 모든 샘플과 달라 보이는 새로운 샘플을 탐지하는 것이 목표
    - Association rule learning(연관 규칙 학습): 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는 학습
- Semi-supervised learning
    
    레이블이 일부만 있는 데이터를 다루는 학습
    
    지도 학습과 비지도 학습의 조합으로 이루어져있음
    
- 자기 지도 학습
    
    레이블이 전혀 없는 데이터 셋에서 레이블이 완전히 부여된 데이터셋을 형성
    
    전체 데이셋에 레이블이 부여된 후 지도 학습 알고리즘을 사용 가능
    
    - 레이블이 없는 이미지로 구성된 대량의 데이터셋이 있다면 각 이미지의 일부분을 랜덤하게 마스킹하고 모델이 원본 이미지를 복원하도록 훈련 (마스킹된 이미지는 모델의 입력으로 사용되고 원본 이미지는 레이블로 사용)
- 강화학습
    
    학습하는 시스템을 Agent라고 부르며 환경을 관찰해서 행동을 실행하고 그 결과로 보상 또는 벌점을 받음
    
    시간이 지나면서 가장 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습 → 주어진 상황에서 agent가 어떤 행동을 선택해야 할지 정의
    

### 배치 학습과 온라인 학습

“입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는가?”

- 배치 학습: 점진적 학습 불가능, 가용한 데이터를 모두 사용해 훈련
    
    모델 부패, 데이터 드리프트(모델의 성능이 감소하는 현상) 발생 가능 → 반복적인 재훈련의 필요성
    
    재훈련이란 새로운 데이터와 기존의 데이터를 포함한 전체 데이터를 사용해 새로운 버전을 처음부터 다시 훈련하는 과정
    
    - 오프라인 학습: 시간과 자원을 많이 소모하고 훈련시킨 다음 제품 시스템에 적용하면 더 이상의 학습이 이루어지지 않음
- 온라인 학습(점진적 학습): 데이터를 순차적으로 한 개씩 또는 미니배치라 부르는 작은 묶음 단위로 주입하여 훈련
    
    데이터의 일부를 읽고 훈련 단계를 수행
    
    매 학습 단계가 빠르고 비용이 적게 듦
    
    - 학습률: 변화하는 데이터에 빠르게 적응하는 능력
        - 학습률이 높을 경우, 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊어버림
        - 학습률이 낮을 경우, 시스템의 관성이 커져 더 느리게 학습하지만 새로운 데이터에 있는 잡음이나 대표성 없는 데이터 포인트에 덜 민감해짐
    - 외부 메모리 학습: 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋에서 모델 훈련이 가능, 보통 오프라인으로 실행

### 사례 기반 학습과 모델 기반 학습

일반화(Generalization/ 좋은 예측을 만드는)되는 방법에 대한 분류 

- 사례 기반 학습: 단순히 기억하는 것 (사용자가 스팸이라고 지정한 메일과 동일한 모든 메일을 스팸으로 분류)
    
    시스템이 훈련 샘플을 기억함으로써 학습
    
    유사도를 측정해 구분하는 방법(스팸 메일과 유사한 메일을 구분하도록 스팸 필터를 프로그래밍하는 방법)
    
- 모델 기반 학습: 이 샘플들의 모델을 만들어 예측에 사용하는 것
    - Example: “돈이 사람을 행복하게 만드는지?”에 대한 조사
        
        ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4dd252a3-b085-498c-82e5-d9b17ba77910/d34b2210-6866-4a42-bcec-3740dfcabd3a/Untitled.png)
        
        → 데이터가 흩어져 있지만 삶의 만족도는 국가의 1인당 GDP가 증가할수록 선형으로 상승
        
        1. 1인당 GDP의 선형 함수로 삶의 만족도를 모델링 (모델 선택) ↔ 1인당 GDP라는 특성 하나를 가진 삶의 만족도에 대한 선형 모델을 선택
        2. 모델이 얼마나 좋은지 특정하는 효용함수(utility function/ 적합도 함수, fitness function)을 정의하거나 얼마나 나쁜지 특정하는 비용 함수(cost function)를 정의해 모델 파라미터 값을 조정
            - 선형 회귀(linear regression) 알고리즘을 사용해 알고리즘에 훈련 데이터를 공급하고 가장 잘 맞는 선형 모델의 파라미터를 찾음 → 훈련(training 과정)

### 머신러닝 프로젝트의 형태

1. 데이터를 분석
2. 모델을 선택
3. 훈련 데이터로 모델을 훈련 (학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾는 과정)
4. 잘 일반화되기를 기대하며 새로운 데이터에 모델을 적용해 예측을 만듦 (추론)

# 머신러닝의 주요 도전 과제

### 충분하지 않은 양의 훈련 데이터

- 대부분의 머신러닝 알고리즘이 잘 작동하려면 매우 많은 데이터가 필요

### 대표성 없는 훈련 데이터

훈련 데이터가 일반화하고 싶은 새로운 사례를 잘 대표하는 것이 중요 

- 기존 예시(대표성 없는 훈련 데이터)에 더 많은 데이터를 추가하면 모델이 크게 변경됨 → 간단한 선형 모델은 잘 작동하지 않음
- 샘플이 작을 경우 샘플링 잡음(우연에 의한 대표성 없는 데이터)이 생기고 매우 큰 샘플도 추출 방법에 따라 샘플링 편향(샘플이 대표성을 띄지 않음) 발생 가능

### 낮은 품질의 데이터

훈련 데이터가 오류, 이상치, 잡음으로 가득하다면

- 데이터 정제 과정이 필수
    - 일부 샘플이 이상치라는 게 명확하면 간단히 해당 샘플들을 무시하거나 수동으로 잘못된 것을 고쳐야 함
    - 일부 샘플에 특성 몇 개가 빠져있다면 이 특성을 모두 무시할지, 이 샘플을 무시할지, 빠진 값을 채울지, 또는 이 특성을 넣은 모델과 제외한 모델을 훈련시킬 것인지 결정과정이 필요

### 관련없는 특성

머신러닝 프로젝트의 핵심 중 하나는 특성 공학 과정(훈련에 사용할 좋은 특성들을 찾는 것)

- 특성 선택: 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택
- 특성 추출: 특성을 결합해 더 유용한 특성을 만듦 (차원 축소 알고리즘)
- 데이터 수집: 개로운 데이터를 수집해 새 특성을 만듦

### 훈련 데이터 과대 적합

과대적합(= 과도한 일반화): 모델이 훈련 데이터에는 너무 잘 맞지만 일반성이 떨어지는 현상 → 데이터의 양과 잡음에 비해 모델이 너무 복잡할 때 발생 

- 심층 신경망 같은 복잡한 모델은 데이터에서 미묘한 패턴을 감지할 수 있지만, 훈련 잡음이 많거나 데이터셋이 너무 작은 경우 샘플링 잡음이 발생
- 해결 방법
    - 규제(모델 단순화,  regularization): 파라미터 수가 적은 모델을 선택, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가하는 방법 등
        - 하이퍼파라미터(규제의 양, hyperparameter): 학습 알고리즘의 파라미터로 클수록 기울기가 0에 가까운 모델을 생성 (과대적합으로부터 안전)
    - 훈련 데이터를 더 많이 모으기
    - 훈련 데이터의 잡음을 줄이기

### 훈련 데이터 과소적합

모델이 너무 단순해 데이터의 내재된 구조르 학습하지 못할 때 발생

- 해결 방법
    - 모델 파라미터가 더 많은 강력한 모델을 선택
    - 학습 알고리즘에 더 좋은 특성을 제공(특성 공학)
    - 모델의 제약을 줄이기(규제 파라미터의 감소)

# 테스트와 검증

모델이 새로운 샘플에 얼마나 잘 일반화될지 알 수 있는 유일한 방법은 새로운 샘플에 실제로 적용해보는 것

- 훈련 데이터를 훈련 세트와 테스트 세트 두 개로 나눈 뒤 훈련 세트로 모델을 훈련, 테스트 세트를 사용해 모델을 테스트
- 일반화 오차(generalization error/ 외부 샘플 오차, out-of-sample error): 새로운 샘플에 대한 오차 비율
- 테스트 세트에서 모델을 평가함으로써 오차에 대한 추정값(estimation)을 얻음
- 과대적합인 경우 훈련 오차는 작지만 일반화 오차는 큼

### 하이퍼파라미터 튜닝과 모델 선택

문제: 일반화 오차를 테스트 세트에서 여러번 측정했으므로 모델과 하이퍼파라미터가 테스트 세트에 최적화된 모델을 만들경우 모델이 새로운 데이터에 잘 작동하지 않을 수 있음 

- 홀드아웃 검증(holdout validation): 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 모델을 선택
    - 이 때 사용되는 홀드아웃 세트는 검증세트(validation set/ 개발 세트, development set/ 데브 세트, dev set)라고 부름
    - 전체 훈련 세트에서 검증 세트를 뺀 데이터에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련하고 검증 세트에서 가장 높은 성능을 내는 모델을 선택
    - 홀드아웃 검증 과정이 끝나면 최선의 모델을 전체 훈련 세트에서 다시 훈련해 최종 모델을 만듦
    - 마지막으로 최종 모델을 테스트 세트에서 평가
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4dd252a3-b085-498c-82e5-d9b17ba77910/02dc123a-385b-41e9-8394-82bf9d8b13f4/Untitled.png)
    
    - 검증 세트의 크기 문제를 해결하기위해 교차 검증을 수행: 작은 검증 세트 여러 개를 사용해 검증 과정을 반복

### 데이터 불일치

데이터의 대표성이 떨어지는 경우 

- 검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가장 잘 대표해야 함
    - 검증 셋트와 테스트 세트는 대표성을 가진 사진으로 구성→ 이 사진을 섞어 반은 검증 세트에 반은 테스트 세트에 넣어줌
- 해결 방법
    - 훈련-개발 세트(train-dev set): 훈련 사진의 일부를 뗴어내 또 다른 세트를 만드는 것
        - 모델을 훈련 세트에서 훈련한 다음 훈련-개발 세트에서 평가: 모델이 잘 작동하지 않을 경우 훈련 세트에 과대적합된 경우
        - 잘 작동할 경우 검증 세트를 통해 평가: 성능이 나쁘다면 데이터 불일치가 원인

# 연습문제

1. 머신러닝이란 데이터로부터 학습할 수 있는 시스템을 만드는 것
2. 명확한 해결책이 없는 복잡한 문제, 수작업으로 만든 긴 규칙 리스트를 대체 등
3. 답이 레이블 형태로 저장된 데이터의 집합
4. regression, classification
5. Hierarchical clustering, visualization, dimensionality reduction, outlier detection
6. 강화 학습
7. 그룹을 정의하는 방법을 모를 경우, 군집 알고리즘(비지도 학습)을 사용하고 그루을 알고 있다면 분류 알고리즘(지도 학습)을 사용
8. 지도 학습, 알고리즘에 많은 이메일과 이에 상응하는 레이블이 제공
9. 배치 학습 시스템과 달리 점진적으로 학습 가능 → 변화하는 데이터와 자율 시스템에 빠르게 적응하고 매우 많은 양의 데이터를 훈련 가능
10. 외부 메모리를 사용해 다량의 데이터를 저장해두고 학습하는 방법
11. 사례 기반 학습 시스템은 훈련 데이터를 기억하고 새로운 샘플과 유사도를 측정해 비슷한 것을 예측으로 사용
12. 모델 파라미터는 모델에 관여를 하고 결정하는 파라미터, 하이퍼파라미터는 모델이 아닌 학습 알고리즘 자체의 파라미터
13. 새로운 샘플에 잘 일반화되기 위한 모델 파라미터의 최적값을 찾고 비용함수를 최소화하며 시스템을 훈련, 예측을 만들기 위해 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측 함수에 새로운 샘플의 특성을 주입
14. 부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터, 무의미한 특성, 훈련 데이터에 과소적합된 모델, 훈련 데이터에 과대적합된 모델 등
15. 과대적합, 더 많은 데이터를 사용, 데이터 단순화, 데
16. 테스트 세트는 배치되기 전에 모델이 새로운 샘플에 대해 만들 일반화 오차를 추정하기 위해 사용 
17. 가장 좋은 모델을 고르기위해 모델을 비교하는데 사용되는 기준
18. 테스트 세트에 사용되는 데이터와 훈련 세트 사이에 데이터 불일치 위험이 있을 경우 사용, 훈련 세트의 일부로 모델을 훈련하고 훈련-개발 세트와 검증 세트에서 평가
19. 테스트 세트를 사용해 하이퍼파라미터를 튜닝할 경우 테스트 세트에 과대적합될 수 있고 일반적 오차를 낙관적으로 측정
