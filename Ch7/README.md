# 앙상블 학습과 랜덤 포레스트

- 앙상블 학습: 일련의 예측기(앙상블)로부터 예측을 수집
    
    → 가장 좋은 모델 하나보다 더 좋은 예측을 얻을 수 있음 
    
    - 예시
        
        훈련 세트로부터 랜덤으로 각기 다른 서브셋을 만들어 일련의 결정 트리 분류기를 훈련
        
        예측을 모아 가장 많은 선택을 받은 클래스를 앙상블의 예측으로 선택
        
- 앙상블 방법: 앙상블 학습 알고리즘
- 랜덤 포레스트: 결정 트리의 앙상블 → 간단하지만 현재 가장 강력한 머신러닝 알고리즘
    
    프로젝트의 마지막에선 흔히 앙상블 방법을 사용해 여러 괜찮은 예측기를 연결해 더 좋은 예측기를 만듦
    

## 1. 투표 기반 분류기

- 직접 투표(hard votin) 분류기: 다수결 투표로 정해지는 분류기
    
    앙상블에 포함된 개별 분류기 중 가장 뛰어난 것보다 정확도가 높은 경우가 많음
    
    - 약한 학습기: 랜덤 추측보다 조금 더 높은 성능을 내는 분류기
    - 강한 학습기: 높은 정확도
    
    → 큰 수의 법칙(반복이 많아질수록 비율이 점점 더 정확해짐)때문에  약한 학습기의 앙상블로 강한 학습기를 만들 수 있음
    
- 정확도는 모든 분류기가 완벽하게 독립적이고 오차에 상관관계가 없어야 가능
    
    → 이같은 경우 같은 데이터로 훈련되기 때문에 불가능
    
    분류기들은 같은 종류의 오차를 만들기 쉽고 잘못된 클래스가 다수인 경우가 많고 앙상블의 정확도가 낮아짐
    
    - 각기 다른 알고리즘으로 학습시키면 다른 종류의 오차를 만들어 앙상블 모델의 정확도가 향상
- sklearn의 VotingClassifier
    - 이 클래스는 모든 추정기를 복제하여 복제된 추정기를 혼련
    - predict() 메서드 호출을 통해 직접 투표 수행 가능
- 간접 투표: 모든 분류기가 확률을 예측할 수 있을 경우, 개별 분류기의 예측을 편균 내어 확률이 가장 높은 클래스를 예측
    
    → 확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식보다 성능이 높음
    
    - 투표 기반 분류기의 “voting=soft”로 설정하고 모든 분류기가 클래스의 확률을 추정하도록 하기

## 2. 배깅과 페이스팅

다양한 분류기를 만드는 방법 중 하나는 같은 알고리즘을 사용하고 훈련 세트의 서브셋을 랜덤으로 구성하여 분류기를 각기 다르게 학습시키는 것

- 서브셋을 구성하는 방법
    - 배깅(Bootstrap Aggregating): 훈련 세트에서 중복을 허용하여 샘플링하는 방식
    - 페이스팅: 중복을 허용하지 않고 샘플링하는 방식
    
    두 방법모두 같은 훈련 샘플을 여러 개의 예측기에 사용 가능하지만 한 예측기를 위해 같은 훈련 샘플을 여러번 샘플링 하는 것은 배깅만 가능
    
- 집계함수
    - 통계적 최빈값: 일반적으로 분류일 때 사용, 직접 투표 분류기처럼 가장 많은 예측 결과
    - 회귀일 경우 평균을 사용
    
    개별 예측기는 원본 훈련 세트로 훈련시킨 것보다 훨씬 크게 편향되어 있지만 집계함수를 통과하면 편향과 분산이 모두 감소
    
    앙상블의 결과는 하나의 예측기를 훈련시킬 때와 편향은 비슷하지만 분산은 감소
    
- 예측기는 다른 CPU 코어나 서버에서 병렬로 학습 가능 → 확장성이 좋음

### 사이킷런의 배깅과 페이스팅

- 앙상블은 비슷한 편향에서 더 작은 분산을 생성
    
    훈련 세트의 오차 수가 거의 동일하지만 결정 경계는 덜 불규칙
    
- BaggingClassifier(회귀 → BaggingRegressor)
    - n_jobs 매개변수: 훈련과 예측에 사용할 CPU 코어 수 지정 (-1: 가용한 모든 코어)
    - 클래스 확률이 추정 가능하면 직접 투표 대신 자동으로 간접 투표 방식 사용
    - 각 예측기가 학습하는 서브셋에 다양성을 추가하므로 페이스팅보다 편향이 조금 더 높음
        
        하지만 예측들간의 상관관계를 줄이므로 앙상블의 분산이 감소
        
        → 전반적으로 배깅이 더 선호됨
        

### OOB 평가

- 배깅의 샘플 선택 방식
    
    평균적으로 각 예측기에 훈련 샘플의 63% 정도만 샘플링
    
    - OOB(out-of-bag) 샘플: 선택되지 않은 37%의 샘플
        
        이 샘플들은 훈련 과정에 참여하지 않으므로 예측기 평가에 사용 가능
        
    - 앙상블의 평가: 각 OOB 평가를 평균
        
        BaggingClassifier의 “oob_score=True”를 통해 OOB 평가 수행 가능
        

## 3. 랜덤 패치와 랜덤 서브스페이스

- BaggingClassifier가 지원하는 특성 샘플링
- max_features, bootstrap_features 두 매개변수로 조절
    
    max_samples, bootstrap과 동일하지만 특성에 대한 샘플링에 사용
    
    → 각 예측기는 랜덤으로 선택한 입력 특성의 일부분으로 훈련
    
- 훈련 속도를 크게 높일 수 있으므로 매우 고차원의 데이터 셋에 유리
- 랜덤 패치 방식: 훈련 특성과 샘플을 모두 샘플링
- 랜덤 서브스페이스 방식: 훈련 샘플을 모두 사용하고 특성을 샘플링하는 것
- 특성 샘플링은 더 다양한 예측기를 만들며 편향을 늘리고 분산을 낮춤

## 4. 랜덤 포레스트

일반적으로 배깅 배깅 방법(또는 페이스팅)을 적용한 결정 트리의 앙상블

- max_samples를 훈련 세트의 크기로 지정
- RandomForestClassifier(회귀 → RandomForestRegressor)
    
    DecisionTreeClassifier와 BaggingClassifier의 매개변수를 모두 가지고 있음
    
- 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 랜덤으로 선택한 특성 후보 중에서 최적의 특성을 찾음 → 무작위성 주입
    - 기본적으로 $\sqrt(n)$개의 특성(n: 특성 개수)을 선택
        
        → 트리의 다양성 확보와 편향을 대가로 분산을 낮춤
        

### 엑스트라 트리

랜덤 포레스트가 트리를 만들 때 각 노드는 랜덤으로 특성의 서브셋을 만들어 분할에 사용

- 익스트림 랜덤 트리(엑스트라 트리): 극단적으로 랜덤
    
    트리를 더욱 랜덤하게 만들기 위해 최적의 임곗값을 찾는 대신 후보 특성을 사용해 랜덤으로 분할한 다음 그중에서 최상의 분할을 선택
    
    DecisionTreeClassifier의 “splitter=”random””을 사용
    
- 엑스트라 트리의 훈련 속도가 비교적 빠름
    
    가장 최적의 임곗값을 찾는 것은 트리 알고리즘에서 시간이 가장 많이 소요되는 작업
    
- ExtraTreesClassifier를 사용:
    - RandomForestClassifier의 boostrap 매개변수가 False인 버전

### 특성 중요도

특성의 상대적 중요도 측정이 쉬움

- 특성의 중요도: 어떤 특성을 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는지 → 가중치 평균 (가중치 = 연관된 훈련 샘플 수)
- 사이킷런이 자동으로 특성 중요도 점수를 계산하고 합이 1이 되도록 정규화
- 특성을 선택해야 할 경우 어떤 특성이 중요한지 빠르게 확인 가능

## 5. 부스팅

약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법

- 앞의 모델을 보완해 나가며 일련의 예측기를 학습

### AdaBoost(Adaptive Boosting)

이전 모델이 과소적합했던 훈련 샘플의 가중치를 높여 이전 예측기를 보완하는 방법

학습하기 어려운 샘플에 점점 더 맞춰짐 

- AdaBoost 분류기를 만드는 방법
    1. 알고리즘의 기반이 되는 첫 번째 분류기를 훈련 세트에서 훈련시키고 예측을 만듦
    2. 알고리즘이 잘못 분류된 훈련 샘플의 가중치를 상대적으로 높임
    3. 업데이트된 가중치를 사용해 훈련 세트에서 훈련하고 예측을 만듦
    4. 가중치 업데이트
    
    → 위 3, 4번 과정을 반복