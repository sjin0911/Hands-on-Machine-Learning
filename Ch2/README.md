- 예제 프로젝트를 진행해보기
    1. 큰 그림을 보기
    2. 데이터를 구하기
    3. 데이터로부터 인사이트를 얻기 위해 탐색하고 시각화
    4. 머신러닝 알고리즘을 위해 데이터를 준비
    5. 모델을 선택하고 훈련
    6. 모델을 미세 튜닝
    7. 솔루션 제시
    8. 시스템 론칭, 모니터링, 유지보수

## 1. 실제 데이터로 작업하기

- 오픈된 다양한 실제 데이터
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4dd252a3-b085-498c-82e5-d9b17ba77910/761165cf-9b3b-400a-a040-23b6d40eddd5/Untitled.png)
    

## 2. 큰 그림 보기

- 캘리포니아 인구 조사 데이터를 사용해 캘리포니아의 주택 가격 모델을 만드는 것
- 데이터에는 캘리포니아의 블록 그룹(block group), 인구, 중간 소득, 중간 주택 가격 등을 담고 있음

### 문제 정의

**‘비즈니스의 목적이 정확히 무엇인가요?’**

- 이 예시의 경우 구역 데이터를 통해 구역 가격을 결정하고 그 출력이 여러 가지 다른 신호와 함께 다른 머신러닝 시스템(해당 지역의 투자 가치 판단)의 입력으로 사용
- Pipeline: 데이터 처리 컴포넌트들이 연속되어 있는 것
    
    데이터를 조작하고 변환할 일이 많아 파이프라인을 매우 자주 사용
    
    - 컴포넌트들은 비동기적으로 작동하고 각 컴포넌트는 많은 데이터를 추출해 처리하고 그 결과를 다른 데이터 저장소로 보내면 파이프라인의 다음 컴포넌트가 그 데이터를 추출해 자신의 출력 결과를 만듦
    - 각 컴포넌트는 독립적이며 이로 인해 시스템이 이해하기 쉽고 시스템이 매우 견고함

**‘현재 솔루션은 어떻게 구성되어 있나요?’**

- 현재 상황은 문제 해결 방법에 관한 정보를 제공하고 참고 성능으로 사용 가능

**어떤 지도 방식이 필요한지 결정**

- 레이블된 훈련 샘플(기대 출력값을 가지고 있음)이 있으므로 지도 학습 작업이 필요
- 모델이 값을 예측해야 하므로 전형적인 회귀문제
    
    예측에 사용할 특성이 여러개이므로 다중 회귀 문제이자 각 구역마다 하나의 값을 예측하므로 단변량 회귀 문제 (↔ 다변량 회귀 문제)
    
- 데이터에 연속적인 흐름이 없고 빠르게 변하는 데이터에 적용하지 않아도 되며, 데이터가 메모리에 들어갈 만큼 충분히 작으므로 일반적인 배치 학습

### 성능 측정 지표 선택

- 회귀 문제의 전형적인 성능 지표는 평균 제곱근 오차(root mean square error, RMSE)로 오차가 커질수록 큰 값을 가짐
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4dd252a3-b085-498c-82e5-d9b17ba77910/5f3fe026-ee97-4c58-a4cb-d38eee433022/Untitled.png)
    
- RMSE는 일반적으로 회귀 문제에서 선호되는 성능 측정 방법이지만 이상치로 보이는 구역이 많다면 평균 절대 오차(mean absolute error, MAE/ 평균 절대 편차, mean absolute deviation)을 고려
    
    ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4dd252a3-b085-498c-82e5-d9b17ba77910/1a674668-199d-4d5e-8cb0-f47fb8c08354/Untitled.png)
    

→ 두 방법 모두 예측값의 벡터와 타깃값의 벡터 사이의 거리를 재는 방법 

- norm(거리 측정 방법)
    - 유클리드 norm ( $l_2$ norm): 제곱근을 합한 것의 제곱근 계산 (RMSE)
    - manhatten norm ( $l_1$ norm): 절댓값의 합을 계산 → 도시의 구획이 직각으로 나뉘어 있을 때 도시의 두 지점 사이의 거리
    - $l_k$  norm
        
        ![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/4dd252a3-b085-498c-82e5-d9b17ba77910/556b742b-7c48-4626-a08d-97692d54e4ec/Untitled.png)
        
    - norm의 지수가 클수록 큰 값의 원소에 치우치며 작은 값은 무시
        
        → 그러므로 RMSE가 MAE보다 조금 더 이상치에 민감
        

### 가정 검사

지금까지 만든 가정을 나열하고 검사

## 3. 데이터 가져오기

### 구글 코랩을 사용하여 예제 코드 실행하기

### 코드와 데이터 저장하기

### 대화식 환경의 편리함과 위험

### 책의 코드와 노트북의 코드

### 데이터 다운로드

```python
from pathlib import Path
import pandas as pd
import tarfile
import urllib.request

def load_housing_data():
    tarball_path=Path("dataseta/housing.tgz")
    if not tarball_path.is_file():
        Path("datasets").mkdir(parents=True,exist_ok=True)
    
        url="http://github.com//ageron/data/raw/main/housing.tgz"
        urllib.request.urlretrieve(url,tarball_path)
        with tarfile.open(tarball_path) as housing_tarball:
            housing_tarball.extractall(path="datasets")
    return pd.read_csv(Path("datasets/housing/housing.csv"))

housing=load_housing_data()
```

- 데이터를 수동으로 내려받아 압축을 추는 대신 데이터를 가져오기 위해 코드 사용 → 데이터의 업데이트가 자주 이뤄지는 경우 사용하기 적합

### 데이터 구조 훑어보기

### 테스트 세트 만들기

- 데이터 스누핑(data snooping): 사람의 뇌로 테스트 세트를 판단하게 된다면 과대적합될 가능성이 커짐 → 매우 낙관적인 추정
- 랜덤으로 어떤 샘플을 선택해서 데이터셋의 20% 정도를 떼어놓음
- 프로그램을 다시 실행하면 반복적으로 다른 테스트 세트가 생성되고 전체 데이터셋을 보는 셈이 되므로 테스트 세트를 저장하고 유지하는 과정이 필요
    - 테스트 세트를 저장하고 다음번 실행에서 불러들이는 방법
    - 항상 같은 난수 인덱스가 생성되도록 np.random.permutation()을 호출하기 전에 난수 발생기의 초깃값을 지정 np.random.seed(42)
    - 다음번에 업데이트된 데이터셋을 사용할 경우: 샘플의 식별자(샘플이 고유하고 변경 불가능)를 사용하여 테스트 세트로 보낼지 말지 결정
        
        Ex: 각 샘플마다 식별자의 해시값을 계산해 해시 최대값의 20%보다 작거나 같은 샘플만 테스트 세트로 사용 가능하다는 조건을 사용 
        
    
    → 데이터셋이 갱신되더라도 테스트 세트가 동일하게 유지되며 새 샘플의 20%를 갖게 되지만 이전에 훈련 세트에 있던 샘플은 포함시키지 않음
    
- 샘플링 편향을 피하기 위한 샘플링 방식
    - 계층적 샘플링 (stratified sampling): 계층(strata)라는 동질의 그룹으로 나누고 테스트 세트가 전체 샘플을 대표하도록 각 계층에서 올바른 수의 샘플을 추출해 사용하는 방법

## 4. 데이터 이해를 위한 탐색과 시각화

### 지리적 데이터 시각화하기

### 상관관계 조사하기

### 특성 조합으로 실험하기

- 특성을 여러가지로 조합해 상관관계 행렬을 통해 특성간의 관계 파악 가능

## 5. 머신러닝 알고리즘을 위한 데이터 준비

- 데이터 준비를 자동화해야 하는 이유
    1. 어떤 데이터셋에 대해서도 데터 변환을 손쉽게 반복 가능 (재사용)
    2. 향후 프로젝트에 재사용 가능한 변환 라이브러리를 점진적으로 구축 가능
    3. 실제 시스템에서 알고리즘에 새 데이터를 주입하기 전에 이 함수를 사용해 변환 가능
    4. 여러 가지 데이터 변환을 쉽게 시도해볼 수 있고 어떤 조합이 가장 좋은지 확인하는 데 편리

### 데이터 정제

누락된 특성을 다루기 위한 함수 생성

Example: 특성에 값이 없는 경우 해당 구역 제거, 전체 특성 삭제, 누락된 값 채우기(대체) 작업 진행

### 텍스트와 범주형 특성 다루기

- 카테고리별 유사성 특성 문제를 해결하기 위해 카테고리별 이진 특성을 만들어 해결 → 한 특성만 1이고 나머지는 0이 되는 인코딩 (원-핫 인코딩), 새로운 특성은 더미라고 부름

### 특성 스케일과 변환

- 특성 스케일링: 머신러닝 알고리즘은 입력된 숫자 특성들의 스케일이 많이 다를 경우 제대로 작동하지 않기 때문에 특성들의 스케일을 맞춰주는 작업
    - min-max 스케일링 (정규화): 모든 특성에 대해 0~1 범위에 들도록 값을 이동하고 스케일을 조정
        
        사이킷런의 MinMaxScalar 변환기를 사용 (feature_range: 범위 지정 가능)
        
    - 표준화: 평균을 뺀 후 표준편차로 나누는 방법 (표준화된 값의 평균은 항상 0, 표준편차는 항상 1) → 정규화보다 이상치에 영향을 덜 받음
        
        사이킷런의 StandardScaler 사용 (with_mean: 데이터에서 평균을 뺄 지 말 지 결정)
        
    - 꼬리가 두꺼운 분포를 가진 특성일 경우 스케일링하기 전에 두꺼운 꼬리를 줄이도록 데이터를 변환하고 분포가 대략적으로 대칭이 되도록 전환해주어야 함
        - 양수 특성일 경우 특성을 제곱근으로 바꾸거나 로그값을 변환
        - 버킷타이징(buketizing): 분포를 동일한 크기의 버킷으로 자르고 특성값을 해당하는 버킷의 인덱스로 전환 → 멀티모달 분포일 경우
        - 방사 기저 함수 (RBF): 특성의 값과 특정 모드 사이의 유사도를 나타내는 특성을 추가하는 방법
            
            입력값과 고정 포인트 사이의 거리에만 의존하는 함수
            
            일반적으로 입력값이 고정 포인트에서 멀어질수록 출력값이 지수적으로 감소하는 가우스 RBF
            
- 타깃 값이 변환이 필요할 경우
    - 타깃 분포의 꼬리가 두꺼울경우 타깃을 로그값으로 변경 가능 → 회귀 모델이 중간 주택 가격 자체가 아니라 중간 주택 가격의 로그를 예측
        
        중간 주택 가격을 얻고 싶을 경우 모델 예측에 지수함수 적용 필요 → 사이킷런의 역변화 inverse_transform() 메서드 사용
        

### 사용자 정의 변환기

- 어떤 훈련도 필요하지 않는 변환의 경우 넘파이 배열을 입력으로 받고 변환된 배열을 출력하는 함수를 작성
- 사용자 정의 변환 함수를 TransformedTargetRegressor에 사용할 예정이면 inverse_func에 역변환 함수를 지정
- 사용자 정의 변환 함수에 추가적인 매개변수로 하이퍼파라미터 받기 가능
- fit() 메서드에서 특정 파라미터를 학습하고 나중에 transform() 메서드에서 이를 사용하기 위해 훈련 가능한 변환기가 필요할 경우 사용자 정의 클래스를 작성

### 변환 파이프라인

사이킷런이 변환을 순서대로 처리하도록 도와주기 위해 제공하는 Pipeline 클래스

- Pipeline 생성자는 연속적인 단계를 정의하는 이름/ 추정기 쌍(2개의 원소를 가진 튜플)의 리스트를 받음
    - 이름: 이중 밑줄 문자를 포함하지 않으면서 고유하다면 모두 가능 (이중 밑줄 문자는 하이퍼파파미터 튜닝에 사용)
    - 투정기: 마지막을 제외하고 모두 변환기여야 함 (fit_transform() 메서드를 가져야 함), 마지막 추정기는 변환기, 예측기부터 다른 타입의 추정기까지 무엇이든 가능
- 변환기의 이름을 짓고 싶지 않다면 make_pipeline() 함수를 사용: 위치 매개변수로 변환기를 받고 변환기의 클래스 이름을 밑줄 문자 없이 소문자로 변환해 Pipeline 생성
    
    여러 개의 변환기가 같은 이름을 가질 경우 인덱스가 이름 뒤에 추가
    
- Pipeline의 fit() 메서드를 호출하면 모든 변환기의 fit_transform() 메서드를 순서대로 호출하고 마지막 단계에서는 fit() 메서드만 호출
- Pipeline 객체는 마지막 추정기와 동일한 메서드를 제공 (마지막 추정기가 변환기인지 예측기인지에 따라 transform이나 predict 등을 가짐)
- ColumnTransformer: 범주형 열과 수치형 열을 각각 다루지 않고 각 열마다 적절한 변환을 적용하기위해 사용하는 클래스
    - 생성자는 세 개의 원소(이름, 변환기, 변환기가 적용될 열 또는 인덱스 이름)를 가진 튜플의 리스트를 받음
    - 사이킷런이 제공해주는 주어진 타입의 모든 특성들을 자동으로 선택해주는 make_column_selector 클래스 사용 가능
    - 변환기의 이름을 짓고 싶지 않을 경우 make_column_transformer() 함수 사용 가능
- 지금까지 실험한 모든 변환을 수행할 단일 파이프라인이 필요함
    - 대부분의 머신러닝 알고리즘은 누락된 값을 기대하지 않기 때문에 수치형 특성의 경우 누락된 값을 중간 값으로 대체 (범주형 특성의 경우 가장 많이 등장하는 카테고리로 변환)
    - 대부분의 머신러닝 알고리즘이 수치입력을 받기 때문에 범주형 특성을 원-핫 인코딩
    - 비율 특성을 계산해 추가
    - 클러스터 유사도 특성 추가
    - 꼬리가 두꺼운 분포가 존재할 경우 특성을 로그값으로 변환
    - 수치 특성을 표준화 (대부분의 머신러닝 알고리즘은 모든 특성이 대체로 동일한 스케일을 가질 때 작동)

## 6. 모델 선택과 훈련

문제를 정의한 후 데이터를 읽고 탐색 → 훈련 세트와 테스트 세트로 나눔 → 머신러닝 알고리즘에 주입할 데이터를 자동으로 정제하는 파이프라인 작성

### 훈련 세트에서 훈련하고 평가하기

- 선형 회귀 모델
    - 예측 오차가 $68,628
    - 모델이 훈련 데이터에 과소 적합된 사례: 특성들이 충분한 정보를 제공하지 못했거나 모델이 충분히 강력하지 못할 경우
        - 해결법: 더 강력한 모델을 선택, 더 좋은 특성을 주입, 모델의 규제를 감소
- 결정 트리 모델
    - 오차가 0.0 → 모델이 과대적합되었을 가능성이 있음
        - 해결법: 모델을 단순화, 제한, 더 많은 훈련 데이터 사용
- RandomForestRegressor 모델
    - 특성을 랜덤으로 선택해 많은 결정 트리를 만들고 예측의 평균을 구함
    - 이처럼 서로 다른 모델들로 구성된 모델을 앙상블이라고 함

### 교차 검증으로 평가하기

- train_test_split 함수를 사용해 훈련 세트를 더 작은 훈련 세트와 검증 세트로 분리하고 더 작은 훈련 세트에서 모델을 훈련 시키고 검증 세트로 모델을 평가
- k-폴드 교차 검증 (k-fold cross-validaion) 기능을 사용
    - fold라 불리는 중복되지 않은 10개의 subset으로 랜덤으로 분할하고 결정 트리 모델을 10번 훈련하고 매번 다른 폴드를 선택해 평가하고 나머지 9개 폴드는 훈련에 사용 → 10개 평가 점수가 담긴 배열을 도출
    - 모델을 여러 번 훈련시키므로 비용이 비쌈
    
    훈련 오차가 작고 검증 오차는 높음 → 과대 적합
    

⇒ 하이퍼파라미터 조정에 너무 많은 시간을 들이지 않고 여러 종류의 머신러닝 알고리즘에서 다양한 모델을 시도해 가능성 있는 2~5개 정도의 모델을 선정하는 것이 목적

## 7. 모델 미세 튜닝

가능성 있는 모델들을 미세 튜닝

### 그리드 서치

가장 단순한 방법으로 만족할 만한 하이퍼파라미터 조합을 찾을 때까지 수동으로 조정

- 사이킷런의 GridSearchCV를 사용: 탐색하고자 하는 하이퍼파라미터와 시도해볼 값을 지정하면 교차 검증을 통해 가능한 모든 하이퍼파라미터 조합을 평가
- Pipeline이나 ColumnTransformer가 추정기를 겹겹이 감싸고 있더라도 추정기의 모든 하이퍼파라미터를 지정 가능
    - 사이킷런 파이프라인으로 전처리 단계를 감싸면 모델과 전처리 하이퍼파라미터를 같이 튜닝 가능(서로 상호작용하는 관계)

### 랜덤 서치

그리드 서치 방법은 비교적 적은 수의 조합을 탐구할 때 사용하고 하이퍼파라미터 탐색 공간이 커지면 RandomizedSearchCV가 선호됨

- GridSearchCV와 거의 같은 방식으로 사용할 수 있지만 가능한 모든 조합을 시도하는 대신 각 반복마다 하이퍼파라미터에 임의의 수를 대입해 지정한 횟수만큼 평가
- 주요장점
    - 하이퍼파라미터값이 연속적일 경우, 랜덤 서치를 1000번 실행했을 때 각 하이퍼파라미터마다 1000개의 다른 값을 탐색 (그리드 서치는 하이퍼파라미터에 대해 나열한 몇 개의 값을 선택)
    - 간단한 예시: 하이퍼파라미터가 성능 면에서 큰 차이를 만들지 못하지만 그 사실을 알지 못 할 경우, 그리드 서치로 훈련하면 10배 더 오래걸리지만 랜덤 서치에 추가하면 탐색시간이 늘어나지 않음
    - 6개의 하이퍼파라미터에 대해 각각 10개씩 값을 탐색한다면 그리드 서치는 백만 번 모델을 훈련해야하지만 랜덤 서치는 지정한 반복 횟수만큼 실행 가능
- 하이퍼파라미터마다 가능한 값의 리스트나 확률 분포를 제공해야 함
    
    ### HalvingRandomSearchCV와 HalvingGridSearchCV
    
    - 빠르게 훈련하고 대규모 하이퍼파라미터 공간을 탐색하기 위한 계산 자원을 더 효율적으로 사용
    - 작동 방식
        
        첫 번째 반복에서 많은 하이퍼파라미터 조합(=후보)이 그리드 서치나 랜덤 서치로 생성
        
        이 후보들을 사용해 모델을 훈련하고 이전과 같은 방식으로 교차 검증을 사용해 평가
        
        하지만 첫 번째 반복의 속도를 높이기 위해 제한된 자원(모델이 훈련 세트의 작은 일부분에서 훈련, 반복회수를 줄여서 훈련)으로 훈련
        
        모든 후보를 평가한 후에 최상의 후보만 다음 단계로 넘어가 더 많은 자원을 사용하고 몇 번의 반복 후 최종 후보들이 전체 자원을 사용해  평가
        

### 앙상블 방법

최상의 모델을 연결해 보는 방법 

- 결정 트리의 앙상블인 랜덤 포레스트가 결정 트리 하나보다 더 성능이 좋은 것처럼 모델의 그룹(앙상블)이 최상의 단일 모델보다 더 나은 성능을 발휘
- 특히 개별 모델이 각기 다른 형태의 오차를 만드는 경우 더 나은 성능을 발휘
    - k-최근접 이웃 모델을 훈련하고 미세 튜닝한 다음 이 모델의 예측과 랜덤 포레스트의 예측을 평균하여 예측으로 삼는 앙상블 모델을 만들 수 있음

### 최상의 모델과 오차 분석

최상의 모델을 분석해 문제에 대한 인사이트를 얻기 

- RandomForestRegressor는 정확한 예측을 만들기 위한 각 특성의 상대적 주요도 정보를 제공 → 중요하지 않은 특성들을 제거 가능
- sklearn.feature_selection.SelectFromModel 변환기는 자동으로 가장 덜 유용한 특성을 제거 가능
    
    이 변환기는 한 모델(일반적으로 랜덤 포레스트)을 훈련하고 feature_importances_ 속성을 통해 가장 유용한 특성을 선택하고 transform()을 통해 다른 특성을 삭제
    

### 테스트 세트로 시스템 평가하기

테스트 세트의 특성과 레이블을 사용해 final_model을 실행하여 데이터를 변환하고 예측을 만들고 평가하는 과정

- 일반화 오차의 점 추정(point estimate)이 론칭을 결정하기 충분하지 앟을 경우 scipy.stats.t.interval()을 사용해 일반화 오차의 95%의 신뢰구간(confidence interval)을 계산 가능
- 하이퍼파라미터 튜닝을 많이 했다면 교차 검증을 사용해 측정한 것보다 성능이 조금 낮은 것이 보통
- 우리 시스템이 검증 데이터에서 좋은 성능을 내도록 세밀하게 튜닝되었기 때문에 새로운 데이터셋에는 잘 작동하지 않을 가능성이 크지만 현재 예제에서는 테스트 RMSE가 검증 RMSE보다 낮기 때문에 성능이 낮아지지 않았음
    - 테스트 세트에서 성능 수치를 좋게 하려고 하이퍼파라미터를 튜닝하려 시도해서는 새로운 데이터에 일반화되기 어렵기 때문에 안됨

## 8. 론칭, 모니터링, 시스템 유지 보수

제품 시스템에 적용하기 위한 준비(코드 정리, 문서와 테스트 케이스 작성 등)

- 최상의 모델을 저장하고 제품 환경으로 파일을 전달해 로드
    
    joblib 라이브러리 사용
    
    - 원하는 모델로 쉽게 돌아올 수 있도록 실험한 모든 모델을 저장
    - 검증 점수와 검증 세트에 대한 실제 예측도 저장 가능
    
    → 여러 종류의 모델이 만든 점수와 오류의 종류를 비교하기 쉬움
    
- 모델이 제품 환경으로 전달되고 나면 모델이 사용하는 모든 사용자 정의 클래스와 함수를 모두 임포트(코드를 제품 환경으로 전달)하고 모델을 로드해 사용 가능
    - 모델이 웹 사이트 안에서 사용되는 경우
        
        사용자가 새로운 구역에 관한 정보를 입력하고 [가격 예측하기] 버튼을 누를 경우 이 데이터를 포함한 쿼리가 웹 서버로 전송되어 웹 애플리케이션으로 전달
        
        최종적으로 애플리케이션의 코드가 모델의 predict() 메서드를 호출(모델은 서버가 시작될 때마다 로드)
        
    - 웹 애플리케이션이 REST API를 통해 질의할 수 있는 전용 웹 서비스로 모델을 감싸는 경우
        
        주 애플리케이션을 건드리지 않고 모델을 새 버전으로 업그레이드하기 쉬움
        
        필요한 만큼 웹 서비스를 시작하고 웹 어플리케이션에서 웹 서비스로 오는 요청을 로드 밸런싱 가능 → 규모 확장이 쉬움
        
    - 모델을 구글 버텍스 AI와 같은 클라우드에 배포
        
        joblib을 사용해 모델을 저장하고 구글 클라우드 스토리지(GCS)에 업로드
        
        구글 버텍스 AI로 이동해 새로운 모델 버전을 만들고 GCS 파일을 지정
        
        → 로드 밸런싱과 자동 확장을 처리하는 간단한 웹 서비스 완성
        
- 모델의 실전 성능을 모니터링: 모니터링 코드 작성
    - 후속 시스템의 지표로 모델 성능을 추정하는 경우
        
        모델이 추천 시스템의 일부라면 매일 추천 상품의 판매량을 모니터링 
        
    - 모델 성능의 평가를 위해 사람이 필요한 경우
        
        생산 라인에서 여러 제품 결함을 감지하는 이미지 분류 모델을 훈련했을 경우 모델이 분류한 전체 사진 중 한 샘플을 평가하는 사람에게 보냄
        
    
    → 모델이 실패했을 때 무엇을 할지 정의하고 어떻게 대비할지 관련 프로세스를 모두 준비
    
- 모델을 정기적으로 다시 훈련하는 과정에서 자동화할 수 있는 작업들
    - 정기적으로 새로운 데이터를 수집하고 레이블화 (조사원 사용 가능)
    - 모델을 훈련하고 하이퍼파라미터를 자동으로 미세 튜닝하는 스크립트를 작성 → 매일 또는 매주 자동으로 이 스크립트를 실행
    - 업데이트된 테스트 세트에서 새로운 모델과 이전 모델을 평가하는 스크립트를 하나 더 작성 → 성능이 감소하지 않으면 새로운 모델을 제품에 배포 (이 스크립트는 테스트 세트의 여러 서브셋에서 모델의 성능을 테스트)
- 모델의 입력 데이터 품질을 평가
- 남은 모델을 백업
    
    새로운 모델이 어떤 이유로 올바르지 않게 작동하는 경우 이전 모델로 빠르게 롤백하기 위해
    
    새로운 버전의 데이터셋이 오염되었을 경우를 대비해 모든 버전의 데이터셋을 백업
